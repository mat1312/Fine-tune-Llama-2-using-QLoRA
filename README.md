# Fine-tune-Llama-2-using-QLoRA
This repository demonstrates the fine-tuning process of the Llama-2-7b-chat-hf model from Hugging Face using QLoRA (Quantized Low-Rank Adaptation) for efficient parameter tuning and reduced GPU memory usage.
